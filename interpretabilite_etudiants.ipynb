{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224245ad",
   "metadata": {},
   "source": [
    "# Méthodes d'interprétabilité pour les modèles de Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7441a5",
   "metadata": {},
   "source": [
    "## Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574fee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "from pygam import LogisticGAM, s, l\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(2026)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b1f1a",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be64209",
   "metadata": {},
   "source": [
    "Le jeu de données Adult permet d'entraîner des modèles de classification binaire, puisque l'objectif est de prédire si un individu de la base de données gagne un revenu annuel supérieur à 50K dollars ($Y=1$) ou non ($Y=0$). Les données proviennent du recensement américain (U.S. Census), et sont disponibles via la base UCI Machine Learning Repository : https://archive.ics.uci.edu/dataset/2/adult.\n",
    "\n",
    "Le jeu de données Adult contient des informations socio-démographiques, comme par exemple :\n",
    "- l'âge,\n",
    "- le niveau d’éducation,\n",
    "- le statut marital,\n",
    "- la profession de l'individu,\n",
    "- les heures travaillées par semaine\n",
    "- le gain en capital et la perte en capital,\n",
    "- le pays d’origine de l'individu,\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6d0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données : https://archive.ics.uci.edu/dataset/2/adult\n",
    "# Colonnes utilisées pour le modèle de classification\n",
    "cols = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "    \"income\"\n",
    "]\n",
    "\n",
    "adult = pd.read_csv(\"data/adult/adult.data\", names=cols, na_values=\" ?\", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9a71b",
   "metadata": {},
   "source": [
    "Combien y a-t-il de lignes avec des valeurs manquantes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ff232",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = ...\n",
    "print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des lignes avec des valeurs manquantes\n",
    "adult = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'observations et nombre de colonnes dans le jeu de données\n",
    "n_obs, n_cols = ...\n",
    "print(f\"Le jeu de données Adult contient {n_obs} observations et {n_cols} variables, dont la variable cible 'income'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e552511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation des 5 premières lignes du jeu de données\n",
    "adult[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche les types des différentes variables de Adult\n",
    "print(\"Voici le type des différentes variables du jeu de données (catégorielles ou numériques) :\")\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fb6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de variable de type \"object\" : variable catégorielle\n",
    "np.unique(adult[\"workclass\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998a85d",
   "metadata": {},
   "source": [
    "Quelles sont les fréquences empiriques des différentes modalités de la variable à prédire $Y$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5054793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Voici la fréquence de la variable à prédire 'income' :\")\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650f82d",
   "metadata": {},
   "source": [
    "On va transformer la variable cible 'income' en variable binaire 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73354bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable cible (ou variable à prédire)\n",
    "print(adult[\"income\"][:10].to_list())\n",
    "\n",
    "y = (adult[\"income\"] == \">50K\").astype(int).values\n",
    "print(y[:10].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d93fb7",
   "metadata": {},
   "source": [
    "On utilisera seulement quelques variables pour entraîner le modèle de classification :\n",
    "- l'âge,\n",
    "- le niveau d'éducation,\n",
    "- le nombre d'heures travaillées par semaine, \n",
    "- le gain et la perte en capital de l'individu,\n",
    "- et le sexe de l'individu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff288ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection de variables\n",
    "X_df = adult[\n",
    "    [\"age\", \"education_num\", \"hours_per_week\", \"capital_gain\", \"capital_loss\", \"sex\"]\n",
    "].copy()\n",
    "\n",
    "X_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6b447",
   "metadata": {},
   "source": [
    "On va encoder la variabele 'sex' initialement catégorielle en variable numérique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encodage du sexe (one-hot encoding)\n",
    "X_df[\"sex\"] = (X_df[\"sex\"] == \"Male\").astype(int)\n",
    "X_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64acaaa",
   "metadata": {},
   "source": [
    "La catégorie 'Female' devient la catégorie de référence (valeur à 0) et la catégorie 'Male' prend la valeur 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027c74e",
   "metadata": {},
   "source": [
    "On peut ensuite transformer le dataframe pandas des variables explicatives en array numpy, pour faciliter l'entraînement du modèle GAM par la suite, avec les librairies classiques de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4872d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.values\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6accfda5",
   "metadata": {},
   "source": [
    "On peut désormais séparer le jeu de données en une base d'entraînement (70% des observations) et une base de test (30% des observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation en jeu de données d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = ... # utilise random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d876de",
   "metadata": {},
   "source": [
    "## Exemple de modèle interprétable par nature : le GAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda3235",
   "metadata": {},
   "source": [
    "Ici, comme la variable à prédire est binaire, on considérera un GAM Logistique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99118e02",
   "metadata": {},
   "source": [
    "### Premier modèle : GAM univarié"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0f20f",
   "metadata": {},
   "source": [
    "Considérons le premier modèle simplifié n'utilisant que la variable explicative \"age\". On cherche à estimer :\n",
    "$$\\mathbb{P}(Y=1 \\mid \\text{age}) = \\sigma\\!\\Big(\\beta_0\n",
    "+ f_1(\\text{age})\n",
    "\\Big) \\enspace ,$$\n",
    "\n",
    "où $\\sigma$ correspond à la fonction sigmoide :\n",
    "$$\n",
    "\\forall t \\in \\mathbb{R}, \\enspace \\sigma(t)=\\frac{1}{1+e^{-t}} \\in [0,1] \\enspace .\n",
    "$$\n",
    "\n",
    "La fonction inverse de la fonction sigmoide est la fonction logit :\n",
    "$$\n",
    "\\forall p \\in ]0,1[, \\enspace \\text{logit}(p) = \\log\\left(\\frac{p}{1-p}\\right) \\in \\mathbb{R} \\enspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca8fd9",
   "metadata": {},
   "source": [
    "Pour modéliser une spline sur Python, on utilise la fonction $s(.)$, qui correspond à une spline de lissage, notée $f_1$ ci-dessus. En pratique, il n'y a pas autant de nœuds que de points de données dans la base d'apprentissage, sinon le calcul serait trop complexe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6aed60",
   "metadata": {},
   "source": [
    "Dans la fonction $s(.)$ :\n",
    "- le premier terme correspond au numéro de la colonne des variables explicatives de $\\mathbf{X}_{\\text{train}}$ que l'on souhaite modéliser par une spline (ici, la variable \"age\"),\n",
    "- \"spline_order\" correspond à l'ordre des polynômes (par morceaux) qui vont être fittés localement,\n",
    "- \"n_splines\" correspond au nombre de fonctions choisi pour représenter $s(\\text{age}) = \\sum_{j=1}^{\\text{n\\_splines}} \\beta_{j} \\cdot b_{j}(\\text{age})$,\n",
    "- \"lam\" est la valeur du paramètre de lissage $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452608f3",
   "metadata": {},
   "source": [
    "Applique le modèle GAM Logistique présenté ci-dessus avec une spline qui contient 3 fonctions de base et des polynômes de degré 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92debf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "gam = LogisticGAM(\n",
    "    s(0, spline_order = ..., n_splines = ..., lam = .0001) # Terme de spline pour la variable âge\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "gam.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut observer l'effet de la variable \"age\" sur la variable à prédire \"income\"\n",
    "feature_name = \"age\"\n",
    "feature_index = 0\n",
    "# Effet partiel de la variable \"age\" sur les données observées\n",
    "plt.plot(gam.partial_dependence(term=feature_index))\n",
    "\n",
    "plt.title(f\"Effet de {feature_name}\")\n",
    "plt.xlabel(feature_name)\n",
    "plt.ylabel(r\"Effet partiel sur logit($\\mathbb{P}(Y=1)$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28780499",
   "metadata": {},
   "source": [
    "On peut récupérer les 3 coefficients de la fonction $s(.)$ : $\\beta_0$, $\\beta_1$ et $\\beta_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_coef = 0\n",
    "for i, term in enumerate(gam.terms):\n",
    "    # On ignore l'intercept\n",
    "    if term.isintercept:\n",
    "        continue\n",
    "    n_coefs = term.n_coefs\n",
    "    print(\"Nombre de fonctions de base dans la spline : \", n_coefs)\n",
    "    start = i + cpt_coef\n",
    "    cpt_coef += n_coefs\n",
    "    end = i + cpt_coef\n",
    "    coefs = gam.coef_[start:end]\n",
    "    print(f\"Coefficients pour le terme {i} :\\n {coefs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d65d51a",
   "metadata": {},
   "source": [
    "On peut également récupérer les valeurs des différentes fonctions de base sur les points des données d'entraînement, $b_k(\\text{age}_i)$, $i \\in \\{1,\\cdots,n\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice du modèle pour s(0)\n",
    "B_matrix = gam._modelmat(X_train, term=feature_index)\n",
    "print(np.shape(B_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75ce71",
   "metadata": {},
   "source": [
    "Chaque ligne correspond à une observation (une ligne de $\\mathbf{X}_{\\text{train}}$).  \n",
    "Chaque colonne correspond à une fonction de base $b_k(\\cdot)$.  \n",
    "\n",
    "Ainsi, la matrice de design $B_{\\text{matrix}}$ s'écrit :\n",
    "\n",
    "$$\n",
    "B_{\\text{matrix}}[i,k] = b_k(\\text{age}_i)\n",
    "$$\n",
    "\n",
    "où :  \n",
    "- $\\text{age}_i$ est la valeur de la variable \"age\" pour l'observation $i$,  \n",
    "- $b_k$ est la $k$-ième fonction de base de la spline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2a055",
   "metadata": {},
   "source": [
    "\"B_matrix @ coefs_term\" donne directement les valeurs de la fonction spline $s(\\text{age})$ pour toutes les observations ($n = 22792$) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_array = B_matrix.toarray()\n",
    "s_data = B_array @ coefs  # valeur de la spline pour chaque observation\n",
    "print(np.shape(s_data))\n",
    "print(s_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cfad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut tracer la spline obtenue pour la variable âge\n",
    "for term_idx, term in enumerate(gam.terms):\n",
    "    # On ignore le terme intercept\n",
    "    if term.isintercept:\n",
    "        continue  \n",
    "\n",
    "    # Indices des coefficients pour ce terme\n",
    "    start = sum(t.n_coefs for t in gam.terms[:term_idx])\n",
    "    end = start + term.n_coefs\n",
    "    coefs = gam.coef_[start:end]\n",
    "\n",
    "    # Créer une grille pour la variable \"age\"\n",
    "    x_vals = np.linspace(X_train[:, term_idx].min(), X_train[:, term_idx].max(), 200)\n",
    "    \n",
    "    # On crée une grille pour la variable \"age\" (les autres variables sont mises à leur moyenne)\n",
    "    X_grid = np.tile(X_train.mean(axis=0), (200,1))\n",
    "    X_grid[:, term_idx] = x_vals\n",
    "\n",
    "    # Matrice de B-splines pour ce terme\n",
    "    B_grid = gam._modelmat(X_grid, term=term_idx).toarray()\n",
    "\n",
    "    # Fonction spline reconstruite\n",
    "    s_grid = B_grid @ coefs\n",
    "\n",
    "    # --- Tracer ---\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(x_vals, s_grid, color='blue', label='Spline estimée')\n",
    "    # Tracer chaque spline de base (b_j)\n",
    "    for k in range(B_grid.shape[1]):\n",
    "        plt.plot(x_vals, B_grid[:,k], linestyle='--', alpha=0.5, label=f'b{k}' if k<=5 else \"\")\n",
    "    plt.scatter(X_train[:, term_idx], s_data, s=5, alpha=0.3, color='red', label='Observations')\n",
    "    plt.title(f\"Spline pour {feature_name}\")\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel(r\"Effet partiel sur logit($\\mathbb{P}(Y=1)$)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62a43a8",
   "metadata": {},
   "source": [
    "On peut faire varier la valeur de $\\lambda$ pour voir l'effet sur la spline obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474364b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs de lambda à tester\n",
    "lambda_values = [0.01, 0.5, 3, 100]\n",
    "\n",
    "# Couleurs pour chaque courbe\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "# Indices et noms\n",
    "feature_name = \"age\"\n",
    "feature_index = 0\n",
    "\n",
    "for lam, color in zip(lambda_values, colors):\n",
    "    # Définition du modèle avec la lambda actuelle\n",
    "    gam = LogisticGAM(\n",
    "        s(feature_index, spline_order=2, n_splines=3, lam=...)\n",
    "    )\n",
    "    \n",
    "    # Ajustement du modèle sur les données\n",
    "    gam.fit(X_train, y_train)\n",
    "    \n",
    "    # Tracer la spline estimée (effet partiel de la variable \"age\")\n",
    "    plt.plot(gam.partial_dependence(term=feature_index), color=color, label=f'lambda={lam}')\n",
    "    \n",
    "plt.title(fr\"Effet partiel de {feature_name} pour différentes valeurs de $\\lambda$\")\n",
    "plt.xlabel(feature_name)\n",
    "plt.ylabel(r\"Effet partiel sur logit($\\mathbb{P}(Y=1)$)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42260dbf",
   "metadata": {},
   "source": [
    "On peut également changer l'ordre des polynômes par morceaux et le nombre de splines, et observer l'effet obtenu sur la fonction s(.) fittée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82731f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "gam = LogisticGAM(\n",
    "    s(0, spline_order = ..., n_splines = ..., lam = .0001) # Terme de spline pour la variable âge\n",
    ")\n",
    "# Entraînement du modèle\n",
    "gam.fit(X_train, y_train)\n",
    "# On peut observer l'effet de la variable âge sur la variable à prédire 'income'\n",
    "feature_name = \"age\"\n",
    "feature_index = 0\n",
    "# Effet partiel de la variable \"age\" sur les données observées\n",
    "plt.plot(gam.partial_dependence(term=feature_index))\n",
    "\n",
    "plt.title(f\"Effet de {feature_name}\")\n",
    "plt.xlabel(feature_name)\n",
    "plt.ylabel(r\"Effet partiel sur logit($\\mathbb{P}(Y=1)$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b2986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut tracer la spline obtenue pour la variable âge\n",
    "for term_idx, term in enumerate(gam.terms):\n",
    "    # On ignore le terme intercept\n",
    "    if term.isintercept:\n",
    "        continue  \n",
    "\n",
    "    # Indices des coefficients pour ce terme\n",
    "    start = sum(t.n_coefs for t in gam.terms[:term_idx])\n",
    "    end = start + term.n_coefs\n",
    "    coefs = gam.coef_[start:end]\n",
    "\n",
    "    # Créer une grille pour la variable \"age\"\n",
    "    x_vals = np.linspace(X_train[:, term_idx].min(), X_train[:, term_idx].max(), 200)\n",
    "    \n",
    "    # On crée une grille pour la variable \"age\" (les autres variables sont mises à leur moyenne)\n",
    "    X_grid = np.tile(X_train.mean(axis=0), (200,1))\n",
    "    X_grid[:, term_idx] = x_vals\n",
    "\n",
    "    # Matrice de B-splines pour ce terme\n",
    "    B_grid = gam._modelmat(X_grid, term=term_idx).toarray()\n",
    "\n",
    "    # Fonction spline reconstruite\n",
    "    s_grid = B_grid @ coefs\n",
    "\n",
    "    # --- Tracer ---\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(x_vals, s_grid, color='blue', label='Spline estimée')\n",
    "    # Tracer chaque spline de base (b_j)\n",
    "    for k in range(B_grid.shape[1]):\n",
    "        plt.plot(x_vals, B_grid[:,k], linestyle='--', alpha=0.5, label=f'b{k}' if k<=5 else \"\")\n",
    "    plt.scatter(X_train[:, term_idx], s_data, s=5, alpha=0.3, color='red', label='Observations')\n",
    "    plt.title(f\"Spline pour {feature_name}\")\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel(r\"Effet partiel sur logit($\\mathbb{P}(Y=1)$)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639da1d",
   "metadata": {},
   "source": [
    "### Deuxième modèle GAM multivarié : plusieurs variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1e425",
   "metadata": {},
   "source": [
    "Considérons le deuxième modèle utilisant toutes les variable explicatives. On cherche à estimer :\n",
    "$$\\mathbb{P}(Y=1 \\mid \\mathbf{X}) = \\sigma\\!\\Big(\\beta_0\n",
    "+ f_1(\\text{age})\n",
    "+ f_2(\\text{education})\n",
    "+ f_3(\\text{hours})\n",
    "+ f_4(\\text{capital\\_gain})\n",
    "+ f_5(\\text{capital\\_loss})\n",
    "+ \\beta_s \\,\\text{sex}\n",
    "\\Big) \\enspace .$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noms des colonnes\n",
    "feature_names = list(X_df.columns)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba553ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "gam = LogisticGAM(\n",
    "    s(0) +    # spline avec les paramètres par défaut pour la variable \"age\"\n",
    "    ...  +    # spline avec les paramètres par défaut pour la variable \"education_num\"\n",
    "    ...  +    # spline avec les paramètres par défaut pour la variable \"hours_per_week\" \n",
    "    ...  +    # spline avec les paramètres par défaut pour la variable \"capital_gain\" \n",
    "    ...  +    # spline avec les paramètres par défaut pour la variable \"capital_loss\" \n",
    "    l(5)      # terme linéaire pour la variable \"sex\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a8a9d",
   "metadata": {},
   "source": [
    "On peut trouver la valeur optimale de $\\lambda$ par validation croisée (5-folds par défaut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      "  9% (1 of 11) |##                       | Elapsed Time: 0:00:00 ETA:   0:00:08\n",
      " 18% (2 of 11) |####                     | Elapsed Time: 0:00:01 ETA:   0:00:05\n",
      " 27% (3 of 11) |######                   | Elapsed Time: 0:00:01 ETA:   0:00:04\n",
      " 36% (4 of 11) |#########                | Elapsed Time: 0:00:01 ETA:   0:00:03\n",
      " 45% (5 of 11) |###########              | Elapsed Time: 0:00:02 ETA:   0:00:02\n",
      " 54% (6 of 11) |#############            | Elapsed Time: 0:00:02 ETA:   0:00:02\n",
      " 63% (7 of 11) |###############          | Elapsed Time: 0:00:02 ETA:   0:00:01\n",
      " 72% (8 of 11) |##################       | Elapsed Time: 0:00:03 ETA:   0:00:01\n",
      " 81% (9 of 11) |####################     | Elapsed Time: 0:00:03 ETA:   0:00:00\n",
      " 90% (10 of 11) |#####################   | Elapsed Time: 0:00:03 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticGAM(callbacks=[Deviance(), Diffs(), Accuracy()], \n",
       "   fit_intercept=True, max_iter=100, \n",
       "   terms=s(0) + s(1) + s(2) + s(3) + s(4) + l(5) + intercept, \n",
       "   tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algorithme de validation croisée pour trouver les lambdas optimaux pour la log-vraisemblance\n",
    "gam.gridsearch(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9bb54a",
   "metadata": {},
   "source": [
    "On obtient un $\\lambda$ optimal par variable explicative, même pour le terme linéaire de la variable \"sex\" (pénalisation Ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda optimal : [[np.float64(0.001)], [np.float64(0.001)], [np.float64(0.001)], [np.float64(0.001)], [np.float64(0.001)], [np.float64(0.001)]]\n",
      "Nombre de lambdas :  6\n"
     ]
    }
   ],
   "source": [
    "# Affiche les différents lambdas obtenus\n",
    "print(\"Lambda optimal :\", ...)\n",
    "# Affiche le nombre de lambdas obtenus\n",
    "print(\"Nombre de lambdas : \", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ece07c",
   "metadata": {},
   "source": [
    "On peut tracer les effets des différentes variables explicatives du modèle GAM sur logit($\\mathbb{P}(Y=1)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15246c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)  # 2 lignes x 3 colonnes\n",
    "    \n",
    "    # Effet partiel sur les données observées\n",
    "    pdep, confi = gam.partial_dependence(term=i, X=X_train, width=0.95)\n",
    "    \n",
    "    # Tracer l’effet partiel\n",
    "    #plt.plot(X_train[:, i], pdep, 'o', alpha=0.3, label='Effet partiel')\n",
    "    plt.plot(gam.partial_dependence(term=i))\n",
    "    \n",
    "    #plt.title(f\"Effet de {feature_names[i]}\")\n",
    "    plt.xlabel(feature_names[i])\n",
    "    plt.ylabel(r\"Effet partiel sur logit($\\mathbb{P}(Y=1)$)\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a65cb1",
   "metadata": {},
   "source": [
    "On peut afficher les coefficients $\\beta_{j,k}$, des différentes variables explicatives $X_j$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_coef = 0\n",
    "for i, term in enumerate(gam.terms):\n",
    "    if term.isintercept:\n",
    "        continue\n",
    "    if i == 5:\n",
    "        continue\n",
    "    n_coefs = term.n_coefs\n",
    "    #print(i, n_coefs)\n",
    "    start = i + cpt_coef\n",
    "    cpt_coef += n_coefs\n",
    "    end = i + cpt_coef\n",
    "    #print(start, end)\n",
    "    coefs = gam.coef_[start:end]\n",
    "    print(f\"Coefficients pour le terme de spline {i} : {coefs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8563d",
   "metadata": {},
   "source": [
    "Quel est le nombre de fonctions de base \"n_splines\" utilisé par défaut par scikit-learn dans la fonction $s(.)$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8f9397",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a8d221",
   "metadata": {},
   "source": [
    "On peut tracer à nouveau le terme de spline de la variable \"age\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774657d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term_idx, term in enumerate(gam.terms):\n",
    "    if term.isintercept:\n",
    "        continue  # ignorer le terme constant\n",
    "    \n",
    "    if term_idx == 0:\n",
    "        # Indices des coefficients pour ce terme\n",
    "        start = sum(t.n_coefs for t in gam.terms[:term_idx])\n",
    "        end = start + term.n_coefs\n",
    "        coefs = gam.coef_[start:end]\n",
    "\n",
    "        # Créer une grille pour la feature\n",
    "        x_vals = np.linspace(X_train[:, term_idx].min(), X_train[:, term_idx].max(), 200)\n",
    "        \n",
    "        # Créer X complet pour _modelmat (les autres features = moyenne)\n",
    "        X_grid = np.tile(X_train.mean(axis=0), (200,1))\n",
    "        X_grid[:, term_idx] = x_vals\n",
    "\n",
    "        # Matrice de B-splines pour ce terme\n",
    "        B_grid = gam._modelmat(X_grid, term=term_idx).toarray()\n",
    "\n",
    "        # Fonction spline reconstruite\n",
    "        f_grid = B_grid @ coefs\n",
    "\n",
    "        # --- Tracer ---\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(x_vals, f_grid, color='blue', label='Spline estimée')\n",
    "        # Tracer chaque B-spline de base\n",
    "        for k in range(B_grid.shape[1]):\n",
    "            plt.plot(x_vals, B_grid[:,k], linestyle='--', alpha=0.5, label=f'b{k}' if k<=5 else \"\")\n",
    "        plt.title(f\"Spline pour {feature_names[term_idx]}\")\n",
    "        plt.xlabel(feature_names[term_idx])\n",
    "        plt.ylabel(r\"Effet partiel sur logit($\\mathbb{P}(Y=1)$)\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401e889",
   "metadata": {},
   "source": [
    "On va désormais calculer deux métriques de performance prédictive du modèle GAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur la base d'entraînement\n",
    "y_proba_train = ...\n",
    "y_pred_train = ...\n",
    "\n",
    "# Prédictions sur la base de test\n",
    "y_proba_test = ...\n",
    "y_pred_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9088b",
   "metadata": {},
   "source": [
    "Sur la base d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d8bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc = ...(y_train, y_pred_train)\n",
    "# AUC\n",
    "auc = ...(y_train, y_proba_train)\n",
    "\n",
    "print(f\"Accuracy (train) : {acc:.3f}\")\n",
    "print(f\"AUC (train)      : {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f10146",
   "metadata": {},
   "source": [
    "Sur la base de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = ...(y_test, y_pred_test)\n",
    "auc = ...(y_test, y_proba_test)\n",
    "\n",
    "print(f\"Accuracy (test) : {acc:.3f}\")\n",
    "print(f\"AUC (test)      : {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60227961",
   "metadata": {},
   "source": [
    "## Modèle de classification non interprétable : Forêt Aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2632c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation de la base Adult en bases d'entraînement et de test\n",
    "X_df_train, X_df_test, y_train, y_test = train_test_split(\n",
    "    X_df, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d3a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c09647",
   "metadata": {},
   "source": [
    "A quoi correspondent les paramètres \"n_estimators\" et \"max_depth\" ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce147d4",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef57980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8448152318558706\n",
      "AUC: 0.8749960726618426\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle\n",
    "...\n",
    "\n",
    "# Prédictions du modèle sur la base d'entraînement\n",
    "y_pred_train = ...\n",
    "y_proba_train = ...\n",
    "# Prédictions du modèle sur la base de test\n",
    "y_pred_test = ...\n",
    "y_proba_test = ...\n",
    "\n",
    "# Métriques de performance sur la base de test : accuracy et AUC\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e1939",
   "metadata": {},
   "source": [
    "La fonction de scikit-learn \"RandomForestClassifier\" contient un vecteur associé pour quantifier l'importance des variables explicatives.\n",
    "Pour chaque variable : \n",
    "- on fait la somme des réductions de l'indice de Gini (utilisé pour splitter les noeuds de façon optimale pour chaque arbre composant la forêt) à tous les noeuds où elle est utilisée,\n",
    "- on fait la moyenne de cette somme sur tous les arbres de la forêt,\n",
    "- puis, on normalise sur toutes les variables explicatives pour que la somme des importances fassent 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd80cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose rf_model est ton Random Forest déjà entraîné\n",
    "feature_importances = ...  # array de taille n_features\n",
    "\n",
    "# Mettre en DataFrame pour plus de lisibilité\n",
    "df_importance = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": feature_importances\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(df_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule la somme de l'importance des différentes variables\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b17d28",
   "metadata": {},
   "source": [
    "## Partial Dependence Plot (PDP) pour la Forêt Aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80426ad8",
   "metadata": {},
   "source": [
    "Si on note $\\hat{f}$ le modèle estimé par la Forêt Aléatoire, on peut calculer le PDP de la variable \"age\" à la valeur $z$ :\n",
    "$$\n",
    "\\widehat{\\text{PD}}_{\\text{age}}(z)=\\frac{1}{n}\\sum_{i=1}^n f(\\text{z}, \\mathbf{x}_{i,-\\text{age}}) \\enspace ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple pour la variable 'age'\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    ...,              # modèle entraîné\n",
    "    ...,         # données d'entraînement\n",
    "    features=['age'], # feature à analyser\n",
    "    kind='average',  # moyenne marginale (PDP classique)\n",
    "    grid_resolution=20 # on utilise 20 valeurs de la variable \"age\" pour calculer son PDP\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df903a45",
   "metadata": {},
   "source": [
    "On peut aussi spécifier à la fonction plusieurs variables à la fois pour lesquelles on veut calculer le PDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac66c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(\n",
    "    ...,           # modèle entraîné\n",
    "    ...,            # données d'entraînement\n",
    "    features=..., # liste des variables pour le PDP : \"age\" et \"hours_per_week\"\n",
    "    kind=\"average\",     # \"average\" = PDP classique\n",
    "    grid_resolution=20  # nombre de points pour la grille\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322feee",
   "metadata": {},
   "source": [
    "## Méthode agnostique et locale : SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc22ef",
   "metadata": {},
   "source": [
    "\"TreeExplainer\" est l’explainer TreeSHAP codé sur le package Python SHAP, optimisé pour les modèles basés sur des arbres comme les :\n",
    "- Random Forest,\n",
    "- Gradient Boosting (XGBoost, LightGBM, CatBoost),\n",
    "- Decision Tree.\n",
    "\n",
    "\"TreeExplainer\" est très rapide pour les arbres, contrairement à \"KernelExplainer\" qui s'applique à n'importe quel modèle de machine learning mais qui est généralement plus lent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec00592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TreeSHAP pour Random Forest\n",
    "explainer_shap = ...(rf)\n",
    "# Récupération des valeurs SHAP pour la base de données de test\n",
    "shap_values = explainer_shap.shap_values(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a291220",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(shap_values))   # (n_samples, n_features, 2) car problème de classification binaire\n",
    "print(shap_values[0].shape)    # (n_samples, n_features)\n",
    "print(shap_values[1].shape)    # (n_samples, n_features)\n",
    "print(X_df_test.shape)         # (n_samples, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e93e48a",
   "metadata": {},
   "source": [
    "On peut afficher les valeurs de Shapley pour la variable \"age\" (première variable explicative du modèle), notées $\\phi_1$, pour chacune des observations de l'ensemble de test. \n",
    "\n",
    "Deux valeurs de Shapley sont disponibles par variable et par observation : pour les estimations de $\\mathbb{P}(Y=0)$ et $\\mathbb{P}(Y=1)$. Pour une observation donnée, les deux $\\phi_1$ qui sont symétriques car $\\mathbb{P}(Y=0) = 1-\\mathbb{P}(Y=1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des valeurs SHAP pour la variable \"age\" et les 5 premières observations pour Y=0\n",
    "print(shap_values[...])\n",
    "# Affichage des valeurs SHAP pour la variable \"age\" et les 5 premières observations pour Y=1\n",
    "print(shap_values[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd9ffa",
   "metadata": {},
   "source": [
    "Par la suite, on ne regardera que les valeurs de Shapley pour les prédictions $\\hat{f}(\\mathbf{x}) = \\hat{\\mathbb{P}}(Y=1 \\mid \\mathbf{X}= \\mathbf{x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_class1 = shap_values[...]\n",
    "print(np.shape(shap_values_class1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830ce44",
   "metadata": {},
   "source": [
    "On peut tracer le graphique affichant la moyenne (sur toutes les observations de l'ensemble de test) des valeurs absolues des valeurs SHAP $\\phi_j$ pour chaque feature $j \\in \\{1,\\cdots,6\\}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55283968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance globale\n",
    "shap.summary_plot(..., plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bc3fb",
   "metadata": {},
   "source": [
    "On peut tracer le graphique affichant les valeurs SHAP $\\phi_j$ pour chaque feature $j$ et chacune des observations de l'ensemble de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78247173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importances locales\n",
    "shap.summary_plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2d5e8",
   "metadata": {},
   "source": [
    "On peut aussi tracer le graphique de $\\phi_1$ (pour la variable \"age\") pour l'ensemble des observations de la base de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importances locales\n",
    "shap.dependence_plot(..., shap_values_class1, X_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeur moyenne de la prédiction de la classe positive sur l'ensemble d'apprentissage\n",
    "print(...)\n",
    "# phi_0\n",
    "print(explainer_shap.expected_value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f432c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score prédit pour la première observation (i=0) du jeu de données de test\n",
    "print(...)\n",
    "# Classe prédite pour la première observation (i=0) du jeu de données de test\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs SHAP pour toutes les variables pour l'observation i=0 (pour la classe positive Y=1)\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier la valeur qu'on obtient en faisant la somme des phi_j et de phi_0\n",
    "print(... + np.sum(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2fd15d",
   "metadata": {},
   "source": [
    "On peut également afficher l'influende de chacune des variables sur la prédiction de la première observation ($i=0$) de la base de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer_shap.expected_value[1], shap_values_class1[0], X_df_test.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d6844",
   "metadata": {},
   "source": [
    "On peut aussi s'intéresser à la sixième observation ($i=5$) qui a un score prédit de 0.70 environ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0358bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70319b5e",
   "metadata": {},
   "source": [
    "La fonction \"decision_plot\" trace l’évolution de la prédiction depuis la valeur de base ($\\phi_0$) jusqu’à la prédiction finale en ajoutant la contribution de chaque variable ($\\phi_j$) pour les observations spécifiées. On peut tracer ce graphique pour les trois premières observations de l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdcd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.decision_plot(explainer_shap.expected_value[1], shap_values_class1[:3], X_df_test[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d949c62",
   "metadata": {},
   "source": [
    "## Explication contrefactuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import du package\n",
    "import dice_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ed168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On reforme la base de données d'entraînement en accolant X_train et y_train\n",
    "df = pd.DataFrame(np.column_stack((X_df_train, y_train)), columns=feature_names + [\"Y\"])\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de l'objet DiCE : données\n",
    "d = dice_ml.Data(dataframe = df, continuous_features = feature_names, outcome_name = ...)\n",
    "# Définition de l'objet DiCE : modèle\n",
    "m = dice_ml.Model(model=..., backend='sklearn', model_type='...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531619e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de l'explainer DiCE\n",
    "explainer = dice_ml.Dice(..., ..., method=\"genetic\")\n",
    "# La méthode \"genetic\" peut gérer les variables catégorielles si besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation de la base de test pour laquelle on veut calculer l'explication contrefactuelle\n",
    "query_instance = X_df_test.iloc[[0]]\n",
    "query_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1bd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche la classe prédite pour la première observation de la base de test\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491bc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération de 3 contrefactuels avec Y=1\n",
    "# On spécifie les variables qu'on autorise à changer : 'hours_per_week', 'capital_gain' et 'capital_loss'\n",
    "cf = explainer.generate_counterfactuals(query_instance, total_CFs=3, features_to_vary=...)\n",
    "\n",
    "# On affiche les explications contrefactuelles obtenues\n",
    "cf.visualize_as_dataframe(show_only_changes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3261072",
   "metadata": {},
   "source": [
    "## ICE (PDP local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07bb03",
   "metadata": {},
   "source": [
    "On peut afficher le ICE (ou PDP local) des 10 premières observations de la base d'entraînement pour les variables \"age\" et \"hours_per_week\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(\n",
    "    ..., \n",
    "    ..., \n",
    "    features=..., \n",
    "    kind='individual'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac860710",
   "metadata": {},
   "source": [
    "## Accumulated Local Effects (ALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "309bf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyALE import ale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ecae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique\n",
    "ale = ale(model=rf, X=X_df_train, feature=['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage du tableau de calcul des effets moyens pour chaque valeur de la variable \"age\"\n",
    "ale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
